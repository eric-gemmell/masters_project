{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a97756b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Create & Validate MSA </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio import AlignIO\n",
    "\n",
    "YcaO_HMM_filename = \"../raw_sequences/MSA/YcaO_HMM.hmm\"\n",
    "\n",
    "work_dir = \"../processed_sequences/initial_MSA\"\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "clustalo_output_filename = os.path.join(work_dir,\"clustalo_MSA.fa\")\n",
    "mafft_output_filename = os.path.join(work_dir,\"mafft_MSA.fa\")\n",
    "hmm_output_filename = os.path.join(work_dir,\"hmm_MSA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23682955",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define algorithm and input sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92543015",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_input_filename = \"../processed_sequences/initial_dataset/alignment_input_sequences.txt\"#Don't change me unless you know what you're doing\n",
    "MSA_algorithm = \"hmmalign\" #options include mafft, clustalo, hmmalign\n",
    "\n",
    "\n",
    "custom_alignment_filename = os.path.join(work_dir,\"custom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba11b5",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Run MSA algorithm</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (MSA_algorithm == \"mafft\"):\n",
    "    !mafft  --distout {MSA_input_filename} > $mafft_output_filename\n",
    "elif (MSA_algorithm == \"clustalo\"):\n",
    "    !clustalo -i {MSA_input_filename} --hmm-in={YcaO_HMM_filename} -o {clustalo_output_filename}\n",
    "elif (MSA_algorithm == \"hmmalign\"):\n",
    "    !hmmalign --trim --amino -o {hmm_output_filename+\".sto\"} {YcaO_HMM_filename} {MSA_input_filename}\n",
    "    alignment = AlignIO.read(hmm_output_filename+\".sto\", \"stockholm\")\n",
    "    for i in range(0,len(alignment)):\n",
    "        alignment[i].seq = Seq((str(alignment[i].seq)).upper())\n",
    "    AlignIO.write(alignment, hmm_output_filename+\".fa\", \"fasta\")\n",
    "elif (MSA_algorithm == \"custom\"):\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b69c9c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Rerun MSA for phylogenetic analysis </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc119bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import AlignIO\n",
    "YcaO_HMM_filename = \"../raw_sequences/MSA/YcaO_HMM.hmm\"\n",
    "\n",
    "\n",
    "def remove_gaps(seq_record):\n",
    "    seq = seq_record.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    return SeqRecord(seq_without_gaps, id=seq_record.id, description=seq_record.description)\n",
    "\n",
    "work_dir = \"../processed_sequences/hmm_align_no_cluster_050323/\"\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521cf13",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define algorithm and input sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0112507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MSA_input_filename = \"../processed_sequences/hmm_align_no_cluster_050323/hmmalign_no_cluster_95_ID_initial_MSA.fa\"\n",
    "MSA_algorithm = \"hmmalign\" #options include mafft, clustalo, hmmalign\n",
    "output_MSA_filename = os.path.join(work_dir,\"hmmalign_no_cluster_95_ID_final_MSA.fa\")\n",
    "\n",
    "\n",
    "hmm_temp_filename = os.path.join(work_dir,\"temp_hmm.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (MSA_algorithm == \"mafft\"):\n",
    "    !mafft  --distout {MSA_input_filename} > $mafft_output_filename\n",
    "elif (MSA_algorithm == \"clustalo\"):\n",
    "    !clustalo -i {MSA_input_filename} --hmm-in={YcaO_HMM_filename} -o {output_MSA_filename}\n",
    "elif (MSA_algorithm == \"hmmalign\"):\n",
    "    output_MSA_filename = output_MSA_filename.split(\".fa\")[0]\n",
    "    sequences = [seqrec for seqrec in SeqIO.parse(MSA_input_filename,\"fasta\")]\n",
    "    ungapped_sequences = []\n",
    "    for seq in sequences:\n",
    "        ungapped_sequences.append(remove_gaps(seq))\n",
    "    SeqIO.write(ungapped_sequences, hmm_temp_filename, \"fasta\")\n",
    "    !hmmalign --trim --amino -o {output_MSA_filename+\".sto\"} {YcaO_HMM_filename} {hmm_temp_filename}\n",
    "    alignment = AlignIO.read(output_MSA_filename+\".sto\", \"stockholm\")\n",
    "    for i in range(0,len(alignment)):\n",
    "        alignment[i].seq = Seq((str(alignment[i].seq)).upper())\n",
    "    AlignIO.write(alignment, output_MSA_filename+\".fa\", \"fasta\")\n",
    "elif (MSA_algorithm == \"custom\"):\n",
    "    print()\n",
    "else:\n",
    "    raise Exception(\"Wrong MSA algorithm selected, options are: mafft, clustalo or hmmalign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f63018",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Validate MSA </h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch\n",
    "mpl.rcParams['figure.dpi']= 600\n",
    "\n",
    "helix_data_filename = \"../raw_sequences/secondary_structure_for_MSA_validation.json\"\n",
    "helix_data = []\n",
    "with open(helix_data_filename, \"r\") as f:\n",
    "    helix_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99f69e",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\">Define MSA sequences</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA_filename = mafft_output_filename\n",
    "\n",
    "alignment_sequences = [seqrec for seqrec in SeqIO.parse(MSA_filename,\"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the starting directory\n",
    "root_dir = \"../raw_sequences\"\n",
    "\n",
    "fasta_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if  \"fasta.fa\" in file.lower():\n",
    "            fasta_path = os.path.join(dirpath, file)\n",
    "            name_path = os.path.join(dirpath, \"name.txt\")\n",
    "            \n",
    "            # check if the name file exists\n",
    "            if os.path.isfile(name_path):\n",
    "                # read the content of the name file\n",
    "                with open(name_path, \"r\") as f:\n",
    "                    name = f.read().strip()\n",
    "            else:\n",
    "                raise Exception(f\"Name file not found {name_path}\")\n",
    "            # append the fasta path and the name to the list as a tuple\n",
    "            fasta_paths.append((fasta_path, name))\n",
    "\n",
    "\n",
    "\n",
    "db_dir = os.path.join(work_dir,\"db_data/\")\n",
    "db_filename = os.path.join(db_dir,\"my_blast_db\")\n",
    "db_sequences_filename = os.path.join(db_dir,\"db_sequences.fa\")\n",
    "\n",
    "if not os.path.exists(db_dir):\n",
    "    os.mkdir(db_dir)\n",
    "else:\n",
    "    !rm -rf $db_dir\n",
    "    os.mkdir(db_dir)\n",
    "\n",
    "db_sequences = []\n",
    "for sequence in alignment_sequences:\n",
    "    seq = sequence.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    db_sequences.append(SeqRecord(seq_without_gaps, id=sequence.id, description=sequence.description))\n",
    "SeqIO.write(db_sequences, db_sequences_filename, \"fasta\")\n",
    "!makeblastdb -in {db_sequences_filename} -dbtype prot -out {db_filename}\n",
    "\n",
    "import subprocess\n",
    "\n",
    "path_accessions = []\n",
    "for i in tqdm(range(0,len(fasta_paths)),desc=\"Loading Accession Codes\"):\n",
    "    fasta_path = fasta_paths[i][0]\n",
    "#     print(f\"{i+1}/{len(fasta_paths)} Processing {fasta_path}\")\n",
    "    shortened_path = fasta_paths[i][1]\n",
    "    output = subprocess.run(f\"blastp -db {db_filename} -query {fasta_path} -outfmt '6 sseqid' -max_target_seqs 1 -evalue 1e-50\", shell=True, capture_output=True)\n",
    "    accession_numbers = output.stdout.decode().strip().split(\"\\n\")\n",
    "#     print(f\"Got results:\\n{accession_numbers}\")\n",
    "    path_accessions.append((shortened_path, accession_numbers))\n",
    "    \n",
    "# print(path_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_by_accession(seqs, accession):\n",
    "    for item in seqs:\n",
    "        if item['Accession_Interpro'] == accession.split(\".\")[0]:\n",
    "            return item\n",
    "    return None\n",
    "YcaO_data = []\n",
    "all_annotations_filename = \"../raw_sequences/interpro_all_YcaO_annotated.json\"\n",
    "with open(all_annotations_filename, 'r') as f:\n",
    "    YcaO_data = json.load(f)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "# Set the y-limits\n",
    "ax.set_ylim(0, len(helix_data))\n",
    "negative_xlim = -800\n",
    "positive_xlim = 450\n",
    "ax.set_xlim(negative_xlim, len(alignment_sequences[0])+positive_xlim)\n",
    "ax.set_xticks(range(0, len(alignment_sequences[0]), 200))\n",
    "processed_secondary_structure_data = []\n",
    "rect_height = 4/5\n",
    "for i in tqdm(range(0,len(helix_data))):\n",
    "    file = helix_data[i]\n",
    "    accession = file[\"accession\"]\n",
    "    name = \"\"\n",
    "    for path_accession in path_accessions:\n",
    "        if(path_accession[1][0] == accession):\n",
    "            name = path_accession[0]\n",
    "    ax.annotate(name, (negative_xlim, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=6,\n",
    "                                ha='left', va='center')\n",
    "    \n",
    "    for sequence in alignment_sequences:\n",
    "        if(sequence.id == accession):\n",
    "            seq_info = get_item_by_accession(YcaO_data,accession)\n",
    "            domain_start = seq_info[\"YcaO_domain\"][\"start\"]+1\n",
    "            domain_end = seq_info[\"YcaO_domain\"][\"end\"]+1\n",
    "            actual_pos = domain_start\n",
    "            pos_array = []\n",
    "            for char in sequence.seq:\n",
    "                if char != \"-\":\n",
    "                    actual_pos += 1\n",
    "                pos_array.append(actual_pos)\n",
    "            helix_positions = []\n",
    "            start_helix = 0\n",
    "            for helix in file[\"h\"]:\n",
    "                if(helix[1]>domain_start and helix[2]<domain_end):\n",
    "                    helix_length = helix[2]-helix[1]\n",
    "                    MSA_length = pos_array.index(helix[2])-pos_array.index(helix[1])\n",
    "                    stretch_factor = helix_length/MSA_length\n",
    "                    helix_positions.append([helix[0],pos_array.index(helix[1]),pos_array.index(helix[2])])\n",
    "                    x_start, x_end = pos_array.index(helix[1]),pos_array.index(helix[2])\n",
    "                    rect_width = x_end - x_start\n",
    "                    rect_height = 4/5\n",
    "                    rect = plt.Rectangle((x_start, i), rect_width, rect_height, alpha=stretch_factor)\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.annotate(f'{round(stretch_factor,2)}', (x_start+rect_width/2, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=8,\n",
    "                                ha='center', va='center')\n",
    "                    \n",
    "                else:\n",
    "                    start_helix +=1\n",
    "            sheet_positions = []\n",
    "            for sheet in file[\"b\"]:\n",
    "                if(sheet[1]>domain_start and sheet[2]<domain_end):\n",
    "                    sheet_length = sheet[2]-sheet[1]\n",
    "                    MSA_length = pos_array.index(sheet[2])-pos_array.index(sheet[1])\n",
    "                    stretch_factor = sheet_length/MSA_length\n",
    "                    sheet_positions.append([sheet[0],pos_array.index(sheet[1]),pos_array.index(sheet[2])])\n",
    "                    x_start, x_end = pos_array.index(sheet[1]),pos_array.index(sheet[2])\n",
    "                    rect_width = x_end - x_start\n",
    "                    \n",
    "                    rect = plt.Rectangle((x_start, i), rect_width, rect_height, alpha=stretch_factor,color=\"red\")\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.annotate(f'{round(stretch_factor,2)}', (x_start+rect_width/2, i+rect_height/2),\n",
    "                                color='black', weight='bold', fontsize=8,\n",
    "                                ha='center', va='center')\n",
    "            processed_secondary_structure_data.append({\"accession\":accession,\"h\":helix_positions,\"b\":sheet_positions})\n",
    "\n",
    "# Set the x-limits and remove the y-axis ticks and labels\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Alignment of secondary structure elements in MAFFT Multiple Sequence Alignment')\n",
    "ax.set_xlabel('Residue position')\n",
    "ax.set_ylabel('Protein')\n",
    "# Show the plot\n",
    "legend_elements = [    Patch(facecolor='red', alpha=0.5, label='Beta Sheets'),    Patch(facecolor='blue', alpha=0.5, label='Alpha Helices')]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1676c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_data = np.zeros(len(alignment_sequences))\n",
    "for i in tqdm(range(0,len(alignment_sequences)),desc=\"getting occupancy data\"):\n",
    "    sequence = alignment_sequences[i]\n",
    "    for i in range(0,len(sequence.seq)):\n",
    "        char = sequence.seq[i]\n",
    "        if(char != \"-\"):\n",
    "            occupancy_data[i] += 1\n",
    "\n",
    "occupancy_data = occupancy_data/len(alignment_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(negative_xlim, len(alignment_sequences[0])+positive_xlim)\n",
    "ax.set_xticks(range(0, len(alignment_sequences[0]), 200))\n",
    "im = ax.imshow(np.array([occupancy_data, occupancy_data]), cmap='gray_r', aspect='auto', vmin=0, vmax=1)\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Occupancy of each position in MAFFT MSA')\n",
    "ax.set_xlabel('Residue position')\n",
    "plt.colorbar(im, label='% Occupancy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
