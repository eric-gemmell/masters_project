{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c4ea7b",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\"> Cluster and remove highly similar sequences</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv\n",
    "work_dir = \"../processed_sequences/hmm_align_no_cluster_050323/\"\n",
    "cluster_script_filename = \"../external_scripts/ClusterMSA.py\"\n",
    "\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "def remove_gaps(seq_record):\n",
    "    seq = seq_record.seq\n",
    "    seq_without_gaps = Seq(\"\".join(str(seq).split(\"-\")))\n",
    "    return SeqRecord(seq_without_gaps, id=seq_record.id, description=seq_record.description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1da76",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50920cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_min_size = 5\n",
    "skip_cluster = True\n",
    "overwrite_cluster = False\n",
    "ID_cutoff = 0.95\n",
    "input_MSA_filename = \"../processed_sequences/initial_MSA/hmm_MSA.fa\"\n",
    "dataset_name = \"hmmalign\"\n",
    "\n",
    "\n",
    "if not skip_cluster:\n",
    "    cluster_str = f\"{cluster_min_size}_per_cluster\"\n",
    "else:\n",
    "    cluster_str = \"no_cluster\"\n",
    "cluster_dir = os.path.join(work_dir,dataset_name +f\"_{cluster_str}_clusters\")\n",
    "output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_initial_MSA.fa\")\n",
    "cdhit_input_filename = os.path.join(cluster_dir,\"clustered_sequences.fa\")\n",
    "cdhit_output_filename = os.path.join(cluster_dir,\"cdhit_output.fa\")\n",
    "tree_data_output_filename = os.path.join(work_dir, f\"{dataset_name}_{cluster_str}_{int(ID_cutoff*100)}_ID_tree_data.tsv\")\n",
    "if not os.path.exists(cluster_dir):\n",
    "    os.makedirs(cluster_dir)\n",
    "\n",
    "\n",
    "print(f\"Creating Filtered Dataset for phylogenetic analysis '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_sequences = [seqrec for seqrec in SeqIO.parse(input_MSA_filename,\"fasta\")]\n",
    "for seq in focused_sequences:\n",
    "    seq_id = seq.id.split(\".\")[0]\n",
    "    if(seq_id != seq.id):\n",
    "        raise Exception(\"Names are in the wrong format... check MSA, might need to be rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sequences = []\n",
    "\n",
    "print(f\"Clustering sequences, and filtering out sequences with fewer than {cluster_min_size} sequences\\n\")\n",
    "cluster_script = f\"python {cluster_script_filename} clst -i {input_MSA_filename} -o {cluster_dir} --gap_cutoff 1.0 --min_samples {cluster_min_size}\"\n",
    "print(cluster_script)\n",
    "if(not skip_cluster):\n",
    "    if any(filename.endswith(\".a3m\") for filename in os.listdir(cluster_dir)):\n",
    "        print(f\"Previous instance of cluster detected in {cluster_dir}\\n\")\n",
    "        if overwrite_cluster:\n",
    "            print(f\"Overwriting all files in {cluster_dir}\")\n",
    "            !rm -rf {cluster_dir}\n",
    "            os.makedirs(cluster_dir)\n",
    "            !$cluster_script\n",
    "        else:\n",
    "            print(\"Preserving previously created files, skipping clustering step\")\n",
    "    else:\n",
    "        print(\"Initiating clustering.\")\n",
    "        print(f\"Clustering sequences in {cluster_dir}\")\n",
    "        !$cluster_script\n",
    "\n",
    "    import re\n",
    "    pattern = re.compile(r\"clst_\\d{3}\\.a3m\")\n",
    "    for filename in os.listdir(cluster_dir):\n",
    "        if pattern.match(filename):\n",
    "            file_path = os.path.join(cluster_dir, filename)\n",
    "            seqs = [seqrec for seqrec in SeqIO.parse(file_path,\"fasta\")]\n",
    "            if(len(seqs)>cluster_min_size):\n",
    "                clustered_sequences += seqs\n",
    "else:\n",
    "    print(\"Skipping clustering step as requested, if you do not want this, please set skip_cluster to False!\")\n",
    "    clustered_sequences = copy.deepcopy(focused_sequences)\n",
    "    \n",
    "print(f\"\\nFiltering out sequences without large clusters.\\nOut of {len(focused_sequences)} sequences, {len(clustered_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(clustered_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ungapped_sequences = []\n",
    "for seq in focused_sequences:\n",
    "    ungapped_sequences.append(remove_gaps(seq))\n",
    "\n",
    "SeqIO.write(ungapped_sequences, cdhit_input_filename, \"fasta\")\n",
    "\n",
    "print(f\"Filtering out sequences with >{ID_cutoff*100}% identity.\\n\")\n",
    "!./../external_scripts/cd-hit-v4.8.1-2019-0228/cd-hit -i $cdhit_input_filename -o $cdhit_output_filename -c $ID_cutoff -n 5 -d 0 -T 8 -M 16000\n",
    "\n",
    "cdhit_accessions = [seqrec.id for seqrec in SeqIO.parse(cdhit_output_filename,\"fasta\")]\n",
    "\n",
    "low_similarity_sequences = []\n",
    "for accession in cdhit_accessions:\n",
    "    for seq2 in focused_sequences:\n",
    "        if(seq2.id == accession):\n",
    "            low_similarity_sequences.append(seq2)\n",
    "            break\n",
    "\n",
    "if(len(low_similarity_sequences) != len(cdhit_accessions)):\n",
    "    print(len(low_similarity_sequences), len(focused_sequences))\n",
    "    raise Exception(\"Something has gone wrong, the filtered by id sequences don't map to the same sequences as clustered sequences.\\n Have you run all previous code or overwritten files?\")\n",
    "    \n",
    "print(f\"\\nFiltered out sequences with >{ID_cutoff*100}% identity.\")\n",
    "print(f\"Out of {len(focused_sequences)} sequences, {len(low_similarity_sequences)} remain.\")\n",
    "focused_sequences = copy.deepcopy(low_similarity_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqIO.write(focused_sequences, output_filename, \"fasta\")\n",
    "print(f\"\\nSequences saved in {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e599",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h1 style=\"font-size:36px\" align=\"center\">Tree data creation</h1><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "from tqdm.auto import tqdm\n",
    "import pylev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b53b09",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:24px\"> Define Parameters</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f848c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tree_data_filename = \"../processed_sequences/initial_dataset/tree_data.json\"\n",
    "use_alternate_sequences = True\n",
    "alternate_sequences_filename = \"../processed_sequences/clustal_hmm_5_per_cluster_18022023/seqs11.txt\"\n",
    "\n",
    "\n",
    "\n",
    "if(use_alternate_sequences):\n",
    "    tree_data_output_filename = os.path.join(os.path.dirname(alternate_sequences_filename),\"tree_data.tsv\")\n",
    "    focused_sequences = [seqrec for seqrec in SeqIO.parse(alternate_sequences_filename,\"fasta\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_accessions = [seq.id for seq in focused_sequences]\n",
    "sequence_accessions.sort()\n",
    "with open(total_tree_data_filename) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79c66033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = list(data[sequence_accessions[0]].keys())\n",
    "tree_data = {}\n",
    "tree_data[\"accessions\"] = sequence_accessions\n",
    "for header in headers:\n",
    "    tree_data[header] = []\n",
    "    if(header == \"related_seq\"):\n",
    "        related_sequences = {}\n",
    "        for accession in sequence_accessions:\n",
    "            for related_seq in data[accession][header]:\n",
    "                if(related_seq[1] not in related_sequences):\n",
    "                    related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "                else:\n",
    "                    if(related_sequences[related_seq[1]][1]>related_seq[0]):\n",
    "                        related_sequences[related_seq[1]] = (accession,related_seq[0],related_seq[1])\n",
    "        tree_data[header] = [\"_\"]*len(sequence_accessions)\n",
    "        for related_seq in list(related_sequences.keys()):\n",
    "                index = sequence_accessions.index(related_sequences[related_seq][0])\n",
    "                tree_data[header][index] = related_seq\n",
    "    else:\n",
    "        for accession in sequence_accessions:\n",
    "            tree_data[header].append(data[accession][header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cde2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tree_data_output_filename, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    \n",
    "    # Write header row\n",
    "    writer.writerow(tree_data.keys())\n",
    "    \n",
    "    # Write values rows\n",
    "    rows = zip(*tree_data.values())\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31c451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0456c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
